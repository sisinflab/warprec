# Prompt Generator

You have to rewrite the initial raw prompt located in `Documentation Instructions.md` into a more structured, detailed, and actionable format. The WarpRec repo already contains a documentation raw draft but it is approximative, not clear, confused and written without any sense. The rewritten prompt should be organized into clear sections with specific instructions for each phase of the documentation generation process. Use Markdown formatting to enhance readability and structure. Make sure to include all the necessary details, such as the use of LaTeX for mathematical formulas, the specific content to be included in each phase, and the workflow instructions. The goal is to create a comprehensive guide that can be easily followed to generate the documentation for WarpRec effectively. An example of the expected output prompt structure is provided into another sample file named `Example.md`.

Consider the following changes that need to be made to the initial prompt:
X. **API Reference** Create a new section named "API Reference" where you will provide detailed class and method signatures for all classes and methods in the WarpRec codebase. Generate, for each class and method, the documentation using Autodocs and Napoleon. Ask yourself critical questions about the applicability of these plugins considering that in the docstring you will find links, latex code, markdown and parameters.
X. **Reading the evaluation files and evaluate them** Currently this feature is described under `unpersonalized_recommendation` but it needs to be moved to a separate section, as it is a cross-cutting concern that applies to all recommendation types. In this new section, provide detailed instructions on how to read the evaluation files.
X. **Pipelines Section** Create a new section named "Pipelines" where you will describe in detail the current pipelines implemented in WarpRec, including the Design Pipeline, Training Pipeline, and Evaluation Pipeline. In the Evaluation Pipeline, describe that you can either read the recommendation files (also created by other frameworks) or the trained model checkpoint files, and evaluate them using the evaluation module. Further, provide a pipeline design guide that explains how to design new pipelines, including best practices and common pitfalls to avoid. For each pipeline, provide detailed instructions on how to do this, including any necessary code snippets or examples (including YAML configuration files).
X. **Organization of Metrics and Recommenders Taxonomies** Envision a detailed documentation structure inspired from the one provided in `elliot/docs/source/guide/metrics_intro.rst` and `elliot/docs/source/guide/recommenders.rst`, where you will organize the taxonomies of metrics and recommenders in a clear and structured manner with the links to the corresponding API reference sections.
