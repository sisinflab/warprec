# üåê General Recommenders

The `General Recommenders` module of WarpRec is a collection of `collaborative` and `content-based` models. In the following section you will find the list of available models inside WarpRec with their respective parameters. You can try them as-is, or you can personalize them to fit your experimental needs.

## üìö Table of Contents
- üåÄ [Autoencoders](#üåÄ-autoencoders)
- üìÑ [Content Based](#üìÑ-content-based)
- üï∏Ô∏è [Graph Based](#Ô∏èüï∏Ô∏è-graph-based)
- üë• [KNN (K Nearest Neighbor)](#üë•-knn-k-nearest-neighbor)
- üßä [Latent Factor](#üßä-latent-factor)
- üß† [Neural](#üß†-neural)
- ‚ûñ [Unpersonalized](#‚ûñ-unpersonalized)
- üìå [Summary of Available General Models](#üìå-summary-of-available-general-models)

## üåÄ Autoencoders

Autoencoder models learn compact latent representations of users or items by reconstructing user-item interaction data. These models are particularly effective in sparse recommendation settings.

- [EASE (Embarrassingly Shallow Autoencoder)](autoencoder/ease.py): A simple, closed-form linear model that uses ridge regression to learn item-item similarities. Highly efficient and effective as a collaborative filtering baseline.
```yaml
models:
    EASE:
        l2: 10
...
```
- [AddEASE](autoencoder/addease.py): An extension of the EASE model using side information. It solves two linear problems, increasing the complexity of the underlying task. **This model requires side information to function properly**.
```yaml
models:
    AddEASE:
        l2: 10
...
```
- [CEASE](autoencoder/cease.py): An extension of the EASE model using side information. Extends the EASE problem without adding more complexity. **This model requires side information to function properly**.
```yaml
models:
    CEASE:
        l2: 10
...
```
- [MultiDAE (Multinomial Denoising Autoencoder)](autoencoder/multidae.py): A deep autoencoder trained with dropout for denoising input data. Learns robust latent representations from implicit feedback using a multinomial loss.
```yaml
models:
    MultiDAE:
        intermediate_dim: 600
        latent_dim: 200
        dropout: 1.0
        weight_decay: 0.02
        batch_size: 512
        epochs: 10
        learning_rate: 0.001
...
```
- [MultiVAE (Multinomial Variational Autoencoder)](autoencoder/multivae.py): A probabilistic variant of MultiDAE that models uncertainty in user preferences via variational inference. Useful for capturing diverse user behaviors and providing more personalized recommendations.
```yaml
models:
    MultiVAE:
        intermediate_dim: 600
        latent_dim: 200
        dropout: 1.0
        weight_decay: 0.02
        batch_size: 512
        epochs: 10
        learning_rate: 0.001
        anneal_cap: 0.2
        anneal_step: 200
...
```

## üìÑ Content Based

Content-based models generate recommendations by analyzing item attributes and comparing them with user preferences. These models rely on side information (e.g., tags, descriptions, metadata) to build user profiles and match them with similar items. They're particularly useful in cold-start scenarios or when collaborative signals are sparse.

- [VSM (Vector Space Model)](content_based/vsm.py): A classical content-based recommender that represents items and users in a shared vector space. Items are encoded using TF-IDF or binary features, while user profiles are typically aggregated from consumed items. Recommendations are generated by computing the similarity (e.g., cosine) between user and item vectors. **This model requires side information to function properly**.
```yaml
models:
    VSM:
        similarity: cosine
        user_profile: binary
        item_profile: tfidf
...
```

## üï∏Ô∏è Graph Based

Graph-based recommenders exploit the structure of the user-item interaction graph to infer relationships and make recommendations. These models capture high-order proximity and implicit associations through walks or neighborhood propagation. They are well-suited for uncovering complex patterns in sparse datasets.

- [LightGCN](graph_based/lightgcn.py): A simplified graph convolutional network designed for collaborative filtering. It eliminates feature transformations and nonlinear activations, focusing solely on neighborhood aggregation over the user-item interaction graph. By stacking multiple propagation layers, LightGCN captures high-order connectivity, leading to more accurate recommendations with reduced computational overhead.
```yaml
models:
    LightGCN:
        embedding_size: 64
        n_layers: 2
        weight_decay: 0.0001
        batch_size: 512
        epochs: 50
        learning_rate: 0.001
...
```

- [NGCF](graph_based/ngcf.py): A neural graph-based collaborative filtering model that explicitly captures high-order connectivity by propagating embeddings through the user-item interaction graph. NGCF leverages feature transformation and nonlinear activation to model complex user-item interactions, enhancing recommendation accuracy through deep graph representation learning.
```yaml
models:
    NGCF:
        embedding_size: 64
        weight_decay: 0.
        batch_size: 512
        epochs: 50
        learning_rate: 0.001
        weight_size: [64, 64]
        node_dropout: 0.01
        message_dropout: 0.01
...
```

- [RP3Beta](graph_based/rp3beta.py): A graph-based collaborative filtering model that performs a biased random walk of length 3 on the user-item bipartite graph. It integrates a popularity-based penalization term (beta) to reduce the influence of popular items, resulting in more diverse and personalized recommendations.
```yaml
models:
    RP3Beta:
        k: 10
        alpha: 0.1
        beta: 0.1
        normalize: True
...
```

## üë• KNN (K Nearest Neighbor)

KNN-based models generate recommendations by identifying the most similar users or items based on interaction patterns or side information. These models are simple yet effective, and their performance largely depends on the similarity function and neighborhood size.

- [ItemKNN](knn/itemknn.py): A collaborative item-based KNN model that recommends items similar to those the user has already interacted with. Similarities between items are computed using measures like cosine similarity, and the top-k neighbors are used to score candidates.
```yaml
models:
    ItemKNN:
        k: 10
        similarity: cosine
        normalize: True
...
```

- [AttributeItemKNN](knn/attributeitemknn.py): An item-based KNN variant that incorporates item content (e.g., tags, features) to compute similarities, allowing recommendations even when historical interactions are sparse or unavailable.
```yaml
models:
    AttributeItemKNN:
        k: 10
        similarity: cosine
        normalize: True
...
```

- [UserKNN](knn/userknn.py): A collaborative user-based KNN model that recommends items liked by users with similar interaction histories. The model computes pairwise similarities between users and leverages their preferences to generate recommendations.
```yaml
models:
    UserKNN:
        k: 10
        similarity: cosine
        normalize: True
...
```

- [AttributeUserKNN](knn/attributeuserknn.py): A user-based KNN model that uses content-based profiles (e.g., TF-IDF) to define user similarity. This model is particularly useful in cold-start scenarios or when interaction data is limited.
```yaml
models:
    AttributeUserKNN:
        k: 10
        similarity: cosine
        user_profile: tfidf
        normalize: True
...
```

## üßä Latent Factor

- [ADMMSlim (Alternating Direction Method of Multipliers Sparse Linear Methods)](latent_factor/admmslim.py): An efficient implementation of SLIM using the ADMM optimization algorithm. It learns a sparse item-to-item similarity matrix for the top-N recommendation, balancing interpretability and performance.
```yaml
models:
    ADMMSlim:
        lambda_1: 0.1
        lambda_2: 0.1
        alpha: 0.2
        rho: 0.35
        it: 10
        positive_only: False
        center_columns: False
...
```

- [BPR (Bayesian Personalized Ranking)](latent_factor/bpr.py): A pairwise ranking model that optimizes the ordering of items for each user. BPR is particularly effective for implicit feedback and is trained to maximize the margin between positive and negative item pairs.
```yaml
models:
    BPR:
        embedding_size: 16
        weight_decay: 0.001
        batch_size: 512
        epochs: 20
        learning_rate: 0.001
...
```

- [FISM (Factored Item Similarity Models)](latent_factor/fism.py): A recommendation algorithm that models item-to-item similarity by learning latent representations of items. Instead of explicitly learning user embeddings, FISM represents each user as the weighted average of the items they have interacted with, enabling efficient and accurate personalized recommendations
```yaml
models:
    FISM:
        embedding_size: 16
        alpha: 0.1
        split_to: 5
        weight_decay: 0.0001
        batch_size: 512
        epochs: 50
        learning_rate: 0.001
...
```

- [Slim (Sparse Linear Methods)](latent_factor/slim.py): A collaborative filtering model that learns a sparse item similarity matrix using L1 and L2 regularization. SLIM directly models the relationship between items, making it highly interpretable and effective for top-N recommendation.
```yaml
models:
    Slim:
        l1: 0.2
        alpha: 0.1
...
```

## üß† Neural

Neural recommenders leverage deep learning architectures to model complex, non-linear interactions between users and items. These models can integrate collaborative signals with side information and are especially powerful when trained on large-scale datasets.

- [ConvNCF (Convolutional Neural Collaborative Filtering)](neural/convncf.py): Utilizes the outer product of user and item embeddings to construct a 2D interaction map, which is processed by Convolutional Neural Networks (CNNs) to capture complex and localized patterns in user-item interactions. ConvNCF enhances the expressive power of neural collaborative filtering by modeling structured relationships, making it well-suited for scenarios where fine-grained interaction modeling is critical.
```yaml
models:
    ConvNCF:
        embedding_size: 16
        cnn_channels: [[16, 32]]
        cnn_kernels: [[2, 2]]
        cnn_strides: [[1, 1]]
        dropout_prob: 0.01
        weight_decay: 0.0001
        epochs: 20
        learning_rate: 0.001
...
```

- [NeuMF (Neural Matrix Factorization)](neural/neumf.py): Combines Generalized Matrix Factorization (GMF) with a Multi-Layer Perceptron (MLP) to capture both linear and non-linear user-item interactions. NeuMF is a highly expressive model that can adapt to various patterns in user behavior, making it suitable for both implicit and explicit feedback scenarios.
```yaml
models:
    NeuMF:
        mf_embedding_size: 32
        mlp_embedding_size: 32
        mlp_hidden_size: [64, 32]
        mf_train: True
        mlp_train: True
        dropout: 0.01
        weight_decay: 0.0001
        epochs: 20
        learning_rate: 0.001
        neg_samples: 1
...
```

## ‚ûñ Unpersonalized

Unpersonalized models serve as simple baselines in recommender systems research. They are used to produce reference metric scores against which the performance of actual (personalized) models can be compared.

- [Pop](unpersonalized/pop.py): Recommends the most popular items overall. This model helps assess whether other recommenders are biased towards popularity.
```yaml
models:
    Pop: {}
...
```

- [Random](unpersonalized/random.py): Recommends items at random. This model defines a lower bound for performance metrics, serving as a sanity check during evaluation.
```yaml
models:
    Random: {}
...
```

## üìå Summary of Available General Models

In this section you can find a table summarizing all the models available in WarpRec, along with a brief description.

| Category         | Model                | Description                                                       |
| ---------------- | -------------------- | ----------------------------------------------------------------- |
| üåÄ Autoencoders  | **EASE**             | Linear autoencoder using ridge regression for item similarity.    |
|                  | **AddEASE**          | EASE with side information for improved accuracy.                 |
|                  | **CEASE**            | EASE with side information for improved accuracy.                 |
|                  | **MultiDAE**         | Denoising autoencoder optimized for implicit data.                |
|                  | **MultiVAE**         | Variational autoencoder modeling uncertainty in preferences.      |
| üìÑ Content Based | **VSM**              | Classical content-based model using TF-IDF and cosine similarity. |
| üï∏Ô∏è Graph Based  | **LightGCN**          | Simplified Graph convolutional neural network.                  |
|                 | **NGCF**             | Complex Graph convolutional neural network.                   |
|                 | **RP3Beta**          | Random walk model with popularity penalization.                   |
| üë• KNN           | **ItemKNN**          | Item-based collaborative KNN using similarity metrics.            |
|                  | **AttributeItemKNN** | Item-based KNN using content features.                            |
|                  | **UserKNN**          | User-based collaborative KNN using historical interactions.       |
|                  | **AttributeUserKNN** | User-based KNN using content-derived user profiles.               |
| üßä Latent Factor | **ADMMSlim**         | Sparse item similarity model optimized via ADMM.                  |
|                  | **BPR**              | Pairwise ranking model for implicit feedback.                     |
|                  | **FISM**              | Efficient item similarity model using weighted average as user embeddings. |
|                  | **Slim**             | Interpretable item similarity model with L1/L2 regularization.    |
| üß† Neural        | **ConvNCF**            | Applies CNNs to the outer product of user and item embeddings to capture rich interaction patterns.|
|                   | **NeuMF**            | Hybrid neural model combining GMF and MLP layers.                 |
| ‚ûñ Unpersonalized | **Pop**            | Recommends popular items to all users. Serves as a popularity-based baseline.|
|                   | **Random**            | Recommends items at random. Serves as a performance lower bound.   |
